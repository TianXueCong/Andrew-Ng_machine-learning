# Andrew-Ng Machine Learning Notes  
This is my note on Andrew-Ng's machining learning. Thank you for asking questions.

***
[![](/picture/the_first_week/fig_ML.jpg)][Andrew-Ng-coursera]  
- Author: Guo Guanglu  
- E-mail: 2360889142@qq.com
- QQ: 2360889142  

***
[**Back to github.io**][github.io]
***

***
## Content  
* [The first week content](the_first_week.md)
	* What is the machine learning
		* Supervised learning  
		* Unsupervised learning  
	* Model and cost function
		* Model representation
		* Cost function  
	* Parameter Learning
		* Gradient descent
		* Gradient descent intuiton
		* gradient descent for linear regression
* [The second week content](the_second_week.md)  
	* Multivariate Linear  
		* Multiple features  
		* Gradient descent for multiple variables  
		* Gradient descent in practice I - feaure scaling  
		* Gradient descent in practice II - learning rate  
		* Features and polynomial regression  
	* Computing parameters analytically  
		* Normal equation  
		* Normal equation noninvertibility  
	* Submitting programming assignments
		* Working on and Submitting programming assignments  
* [The third week content](the_third_week.md)  
	* Classification and representation  
		* Classification  
		* Hypothesis representation  
		* Decision boundary  
	* Logistic regression model  
		* Cost function  
		* Simplified cost function and gradient descent  
		* Advanced optimization  
	* Multiclass classification  
		* Multiclass classification:One-vs-all  
	* Solving the problem of overfitting  
		* The problem of overfitting  
		* Cost function  
		* Regularized linear regression  
		* Regularized logistic regression  
* [The fourth week content](the_fourth_week.md)  
	* Neural networks  
		* Model representation I  
		* Model representation II  
	* Applications  
		* Examples and intuitions I  
		* Examples and intuitions II  
		* Multiclass classification  
* [The fifth week content](the_fifth_week.md)  
	* Cost function and backpropagation  
		* Cost function  
		* Backpropagation algorithm  
		* Backpropagation intuition  
	* Backpropagation in practice  
		* Implementation note: unrolling parameters  
		* Gradient checking  
		* Random initialization  
		* Putting it together  
* [The sixth week content](the_sixth_week.md)  
	* Evaluating a learning algorithm  
		* Evaluatinng a hypothesis  
		* Model selection and Train/Validation/Test Sets  
	* Bias vs. variance  
		* Diagnosing Bias vs. variance  
		* Regularization and bias/variance  
		* Learning curves  
		* Deciding what to do next revisited  
	* Building a spam classifier  
		* prioritizing what to work on  
		* Error analysis  
	* Using large data sets  
		* Data for machine learning  
* [The seventh week content](the_seventh_week.md)  
	* Large margin classification  
		* Optimization objective  
		* Large margin intuition  
		* Mathematics behind large margin classification  
	* Kernels  
		* Kernels I  
		* Kernels II  
	* SVM in practice  
		* Using an SVM  
* [The eighth week content](the_eighth_week.md)  
	* Clustring  
		* K-means algorithm  
		* Optimization objective  
		* Random initialization  
		* Choosing the number of clusters  
	* Motivation  
		* Motivation I: data compression  
		* Motivation II: visualization  
	* Principal component analysis  
		* Principal component analysis problem formulation  
		* Principal component analysis algorithm  
	* Applying PCA  
		* Reconstruction from compressed representation  
		* Choosing the number of principal components  
		* Advice for applying PCA  
* [The ninth week content](the_ninth_week.md)  
	* Density estimation  
		* Problem motivation  
		* Gaussian distribution  
		* Algorithm  
	* Building an anomaly detection system  
		* Developing and evaluating an anomaly detection system  
		* Anomaly detection vs supervised learning  
		* Choosing what features to use  
	* Multivariate Gaussian distribution  
		* Multivariate Gaussian distribution  
		* Anomaly detection using the multivariate Gaussian distribution  
	* Predicting movie ratings  
		* Problem formulation  
		* Content based recommendations  
	* Collaborative filtering  
		* Collaborative filtering  
		* Collaborative filtering algorithm  
	* Low rank matrix factroization  
		* Vectrization: low rank matrix factroization  
		* Implementational detiail: mean normalization  
	
		
		

		
		
		


**********
### Reference  
https://www.coursera.org/learn/machine-learning/lecture/db3jS/model-representation  

---------------------------------------------------------
[Andrew-Ng-coursera]:https://www.coursera.org/learn/machine-learning/lecture/db3jS/model-representation "Andrew Ng coursera"
[github.io]:https://guoguanglu.github.io "guoguanglu github.io"

